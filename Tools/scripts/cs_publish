#!/usr/bin/env python

import os, sys, fnmatch, argparse
from pprint import pprint
from JMTucker.Tools.CondorTools import cs_dirs_from_argv, cs_njobs
from JMTucker.Tools.SampleFiles import _enc

parser = argparse.ArgumentParser(description = 'cs_publish: get the staged-out files from condor directories and print out lines for SampleFiles.py',
                                 usage = '%(prog)s [options] condor_dirs')

parser.add_argument('condor_dirs', nargs='*', help='The condor directories.')

parser.add_argument('--dataset', required=True,
                    help='The dataset name to use.')
parser.add_argument('--pattern',
                    help='Glob-style pattern to filter the files, useful if there are multiple files output per job.')
parser.add_argument('--partial', action='store_true',
                    help='If set, partial publishing is allowed.')

options = parser.parse_args()

########################################################################

wds = cs_dirs_from_argv()
if not wds:
    print 'No condor dirs in argv\n'
    parser.print_help()
    sys.exit(1)

publish = {}
samples = []
for wd in wds:
    bd = os.path.basename(wd)
    assert bd.startswith('condor_')
    sample = bd.replace('condor_', '')
    assert not publish.has_key((sample, options.dataset))
    njobs = cs_njobs(wd)
    files = []
    for job in xrange(njobs):
        publish_fn = os.path.join(wd, 'publish_%i.txt' % job)
        if not os.path.isfile(publish_fn):
            if options.partial:
                print 'warning: missing', fn
            else:
                raise IOError('no publish file %s' % publish_fn)
        else:
            for fn in open(publish_fn):
                fn = fn.strip()[fn.find('/store'):]
                if options.pattern is None or fnmatch.fnmatch(os.path.basename(fn), options.pattern):
                    files.append(fn)
    samples.append(sample)

    bn = os.path.basename(files[0]).split('_')[0]
    base = [fn.rsplit('/', 2)[0] for fn in files]
    assert len(set(base)) == 1
    base = base[0]
    nums = [int(fn.rsplit('_',1)[1].split('.root')[0]) for fn in files]
    mx = max(nums)
    code = "[%r + '/%%04i/%s_%%i.root' %% (i/1000,i) for i in xrange(%i)]" % (base, bn, mx+1)
    missing = sorted(set(range(1,mx+1)) - set(nums))
    if missing:
        code = code.replace(']', ' if i not in %r]' % missing)
    l = eval(code)
    assert set(l) == set(files)
    publish[(sample, options.dataset)] = (len(files), code)

print 'new entries:'
for k, (n,c) in publish.iteritems():
    print k, ': (', n, ',', c, ')'
encoded = _enc(publish)
print '\nline for SampleFiles (len(repr(publish)) = %i, len(encoded) = %i):' % (len(repr(publish)), len(encoded))
print "_add('%s')" % encoded
print '\nlines for Samples:'
print 'for x in (%s):' % ', '.join(samples)
print "    x.add_dataset('%s', " % options.dataset + "'/%s/None/None' % x.primary_dataset, 0)"

